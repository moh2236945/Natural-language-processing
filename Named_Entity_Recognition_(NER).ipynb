{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named Entity Recognition (NER).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/ISMKVTq51cdgip63RsQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh2236945/Natural-language-processing/blob/master/Named_Entity_Recognition_(NER).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KVl0qyY1rK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "37212023-6d96-4496-9a39-ea8c9d80ba5c"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-jjx89qwq\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-jjx89qwq\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=35888fa1f6f2eb5994debfac75a888fb905c59370d983b7aa5a7f6bf69beca34\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ua3lbxq0/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRJqRIV829yB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c2a7f394-a197-4040-9eb6-656ea1ae64ec"
      },
      "source": [
        "!pip install sklearn-crfsuite\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.28.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.6)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul0a2tps3dX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "d3387851-460b-49ef-d92c-3f14e16de975"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.17.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=520520250bf7420283e50674d5ccf800dfb23a9456e85edf4c4251a144940ebe\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_QmGKx2zdbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LSTM,Dense,TimeDistributed,Embedding,Bidirectional\n",
        "from keras.models import Model,Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from seqeval.metrics import precision_score,recall_score,f1_score,classification_report\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Bhhp_D3imL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('file.csv',encoding = \"ISO-8859-1\")\n",
        "df=df.fillna(method='ffill')\n",
        "class sentence(object):\n",
        "    def __init__(self,df):\n",
        "        self.n_sent=1\n",
        "        self.df=df\n",
        "        self.empty=False\n",
        "        agg=lambda s:[(w,p,t) for w,p,t in zip(s['Word'].values.tolist(),\n",
        "                                               s['POS'].values.tolist(),\n",
        "                                               s['Tag'].values.tolist())]\n",
        "        self.grouped=self.df.groupby('#Sentence#').apply(agg)\n",
        "        sellf.sentence=[s for s in self.grouped]\n",
        "\n",
        "    def get_text(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUECiF7R5jgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#displaying full sentence\n",
        "getter=sentence(df)\n",
        "sentences=[''.join([s[0] for s in sent)] for sent in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-Th0FC6NEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentence with its pos and tag.\n",
        "sent = getter.get_text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzJUnIms6UOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting all the sentences in the dataset.\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxzg_fzO6ZX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the parameters for LSTM network\n",
        "# Number of data points passed in each iteration\n",
        "batch_size = 64 \n",
        "# Passes through entire dataset\n",
        "epochs = 8\n",
        "# Maximum length of review\n",
        "max_len = 75 \n",
        "# Dimension of embedding vector\n",
        "embedding = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGSn_Q0n6fQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting unique words and labels from data\n",
        "words = list(df['Word'].unique())\n",
        "tags = list(df['Tag'].unique())\n",
        "# Dictionary word:index pair\n",
        "# word is key and its value is corresponding index\n",
        "word_to_index = {w : i + 2 for i, w in enumerate(words)}\n",
        "word_to_index[\"UNK\"] = 1\n",
        "word_to_index[\"PAD\"] = 0\n",
        "\n",
        "# Dictionary lable:index pair\n",
        "# label is key and value is index.\n",
        "tag_to_index = {t : i + 1 for i, t in enumerate(tags)}\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "\n",
        "idx2word = {i: w for w, i in word_to_index.items()}\n",
        "idx2tag = {i: w for w, i in tag_to_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeEHKBYdbXNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting each sentence into list of index from list of tokens\n",
        "X = [[word_to_index[w[0]] for w in s] for s in sentences]\n",
        "\n",
        "# Padding each sequence to have same length  of each word\n",
        "X = pad_sequences(maxlen = max_len, sequences = X, padding = \"post\", value = word_to_index[\"PAD\"])\n",
        "# Convert label to index\n",
        "y = [[tag_to_index[w[2]] for w in s] for s in sentences]\n",
        "\n",
        "# padding\n",
        "y = pad_sequences(maxlen = max_len, sequences = y, padding = \"post\", value = tag_to_index[\"PAD\"])\n",
        "num_tag = df['Tag'].nunique()\n",
        "# One hot encoded labels\n",
        "y = [to_categorical(i, num_classes = num_tag + 1) for i in y]\n",
        "In [34]:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F5IwduCbezL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bidirectional LSTM-CRF Network\n",
        "num_tags = df['Tag'].nunique()\n",
        "# Model architecture\n",
        "input = Input(shape = (max_len,))\n",
        "model = Embedding(input_dim = len(words) + 2, output_dim = embedding, input_length = max_len, mask_zero = True)(input)\n",
        "model = Bidirectional(LSTM(units = 50, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
        "crf = CRF(num_tags+1)  # CRF layer\n",
        "out = crf(model)  # output\n",
        "\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Ysajf9blNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making Checkpoint each epoch to check and save the best model performance till last and also avoiding further\n",
        "# validation loss drop due to overfitting.\n",
        "checkpointer = ModelCheckpoint(filepath = 'model.h5',\n",
        "                       verbose = 0,\n",
        "                       mode = 'auto',\n",
        "                       save_best_only = True,\n",
        "                       monitor='val_loss')\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
        "                    validation_split=0.1, callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgLf05rpbsuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iicb4Pv1bzB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_test_true = np.argmax(y_test, -1)\n",
        "# Convert the index to tag\n",
        "y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n",
        "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))\n",
        "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw3uhyKXb5K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the result\n",
        "\n",
        "with open('word_to_index.pickle', 'wb') as f:\n",
        "    pickle.dump(word_to_index, f)\n",
        "\n",
        "with open('tag_to_index.pickle', 'wb') as f:\n",
        "    pickle.dump(tag_to_index, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}